{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import musdb\n",
    "import essentia\n",
    "import essentia.standard as estd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dataset's Path\n",
    "mus = musdb.DB(root_dir='musdb/')\n",
    "\n",
    "# Load the training tracks\n",
    "train_tracks = mus.load_mus_tracks(subsets=['train'])\n",
    "\n",
    "# Load the test tracks\n",
    "test_tracks = mus.load_mus_tracks(subsets=['test'])\n",
    "\n",
    "# Music Extractor from Essentia\n",
    "frame_size = 1024\n",
    "tcontext = 120 #in number of frames\n",
    "extractor = estd.Extractor(lowLevelFrameSize = int(frame_size*tcontext), lowLevelHopSize = int(frame_size*tcontext/4), rhythm = False, highLevel = False )\n",
    "\n",
    "# Order of selected features\n",
    "intraFrame_features = ['lowLevel.barkbands', 'lowLevel.barkbands_kurtosis', 'lowLevel.barkbands_skewness', 'lowLevel.barkbands_spread', \n",
    "                       'lowLevel.dissonance', 'lowLevel.hfc', 'lowLevel.mfcc', 'lowLevel.pitch', 'lowLevel.pitch_instantaneous_confidence', \n",
    "                       'lowLevel.pitch_salience', 'lowLevel.sccoeffs', 'lowLevel.scvalleys', 'lowLevel.silence_rate_20dB', \n",
    "                       'lowLevel.silence_rate_30dB', 'lowLevel.silence_rate_60dB', 'lowLevel.spectral_centroid', 'lowLevel.spectral_complexity', \n",
    "                       'lowLevel.spectral_crest', 'lowLevel.spectral_decrease', 'lowLevel.spectral_energy', 'lowLevel.spectral_energyband_high', \n",
    "                       'lowLevel.spectral_energyband_low', 'lowLevel.spectral_energyband_middle_high', 'lowLevel.spectral_energyband_middle_low', \n",
    "                       'lowLevel.spectral_flatness_db', 'lowLevel.spectral_flux', 'lowLevel.spectral_kurtosis', 'lowLevel.spectral_rms', \n",
    "                       'lowLevel.spectral_rolloff', 'lowLevel.spectral_skewness', 'lowLevel.spectral_spread', 'lowLevel.spectral_strongpeak', \n",
    "                       'lowLevel.zerocrossingrate', 'sfx.inharmonicity', 'sfx.oddtoevenharmonicenergyratio', 'sfx.tristimulus']\n",
    "\n",
    "with open(\"features_length.txt\", 'r') as f:\n",
    "    features_length = [line.rstrip('\\n') for line in f]\n",
    "    \n",
    "def extract_features(track, intraFrame_features, label):\n",
    "    # Cast to 32 bits and then, to Essentia array in order to apply the Extractor algorithm\n",
    "    track = np.float32(track)\n",
    "    track = essentia.array(track)\n",
    "    pool = extractor(track)\n",
    "    # First feature assignment \n",
    "    features = pool[intraFrame_features[0]]\n",
    "    for i in intraFrame_features[1:]:\n",
    "        # If not multidimensional feature, expands dimensions to allow concatenation\n",
    "        if len(pool[i].shape) > 1:\n",
    "            features = np.concatenate((features, pool[i]), axis = 1)\n",
    "        else:\n",
    "            features = np.concatenate((features, np.expand_dims(pool[i], axis = 1)), axis =1)\n",
    "    # Adds the frame's label column\n",
    "    features = np.concatenate((features, np.expand_dims(np.tile(label, features.shape[0]), axis = 1)), axis = 1)\n",
    "    return features\n",
    "\n",
    "features = np.ndarray([], dtype = 'float32')\n",
    "for i, track in enumerate(train_tracks):\n",
    "    # Train tracks: Downmix to mono and feature extraction\n",
    "    # Vocals\n",
    "    aux = track.targets['vocals'].audio[:,0]*0.5 + track.targets['vocals'].audio[:,1]*0.5\n",
    "    # if first iteration, it does not concatenate (empty array)\n",
    "    if i == 0:\n",
    "        features = extract_features(aux, intraFrame_features, 0)\n",
    "    else:\n",
    "        features = np.concatenate((features, extract_features(aux, intraFrame_features, 0)))\n",
    "    # Drums\n",
    "    aux = track.targets['drums'].audio[:,0]*0.5 + track.targets['drums'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 1)))\n",
    "    # Bass\n",
    "    aux = track.targets['bass'].audio[:,0]*0.5 + track.targets['bass'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 2)))\n",
    "    # Other\n",
    "    aux = track.targets['other'].audio[:,0]*0.5 + track.targets['other'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 3)))\n",
    "    print(str(len(train_tracks) - i-1) + ' train tracks remaining')\n",
    "\n",
    "\n",
    "\n",
    "for i, track in enumerate(test_tracks):\n",
    "    # Test tracks: Downmix to mono and feature extraction\n",
    "    # Vocals\n",
    "    aux = track.targets['vocals'].audio[:,0]*0.5 + track.targets['vocals'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 1)))\n",
    "    # Drums\n",
    "    aux = track.targets['drums'].audio[:,0]*0.5 + track.targets['drums'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 1)))\n",
    "    # Bass\n",
    "    aux = track.targets['bass'].audio[:,0]*0.5 + track.targets['bass'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 2)))\n",
    "    # Other\n",
    "    aux = track.targets['other'].audio[:,0]*0.5 + track.targets['other'].audio[:,1]*0.5\n",
    "    features = np.concatenate((features, extract_features(aux, intraFrame_features, 3)))\n",
    "    print(str(len(test_tracks) - i-1) + ' test tracks remaining')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save array\n",
    "np.save('features_tcontext_' + str(tcontext) + '_frameSize_' + str(frame_size) + '.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import musdb\n",
    "import essentia\n",
    "import essentia.standard as estd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dataset's Path\n",
    "mus = musdb.DB(root_dir='musdb/')\n",
    "\n",
    "# Load the training tracks\n",
    "train_tracks = mus.load_mus_tracks(subsets=['train'])\n",
    "\n",
    "# Load the test tracks\n",
    "test_tracks = mus.load_mus_tracks(subsets=['test'])\n",
    "\n",
    "# Music Extractor from Essentia\n",
    "frame_size = 1024\n",
    "tcontext = 120 #in number of frames\n",
    "extractor = estd.Extractor(lowLevelFrameSize = int(frame_size*tcontext), lowLevelHopSize = int(frame_size*tcontext), rhythm = False, highLevel = False )\n",
    "\n",
    "# Order of selected features\n",
    "intraFrame_features = ['lowLevel.barkbands', 'lowLevel.barkbands_kurtosis', 'lowLevel.barkbands_skewness', 'lowLevel.barkbands_spread', \n",
    "                       'lowLevel.dissonance', 'lowLevel.hfc', 'lowLevel.mfcc', 'lowLevel.pitch', 'lowLevel.pitch_instantaneous_confidence', \n",
    "                       'lowLevel.pitch_salience', 'lowLevel.sccoeffs', 'lowLevel.scvalleys', 'lowLevel.silence_rate_20dB', \n",
    "                       'lowLevel.silence_rate_30dB', 'lowLevel.silence_rate_60dB', 'lowLevel.spectral_centroid', 'lowLevel.spectral_complexity', \n",
    "                       'lowLevel.spectral_crest', 'lowLevel.spectral_decrease', 'lowLevel.spectral_energy', 'lowLevel.spectral_energyband_high', \n",
    "                       'lowLevel.spectral_energyband_low', 'lowLevel.spectral_energyband_middle_high', 'lowLevel.spectral_energyband_middle_low', \n",
    "                       'lowLevel.spectral_flatness_db', 'lowLevel.spectral_flux', 'lowLevel.spectral_kurtosis', 'lowLevel.spectral_rms', \n",
    "                       'lowLevel.spectral_rolloff', 'lowLevel.spectral_skewness', 'lowLevel.spectral_spread', 'lowLevel.spectral_strongpeak', \n",
    "                       'lowLevel.zerocrossingrate', 'sfx.inharmonicity', 'sfx.oddtoevenharmonicenergyratio', 'sfx.tristimulus']\n",
    "\n",
    "with open(\"features_length.txt\", 'r') as f:\n",
    "    features_length = [line.rstrip('\\n') for line in f]\n",
    "    \n",
    "def extract_features(track, intraFrame_features, label):\n",
    "    # Cast to 32 bits and then, to Essentia array in order to apply the Extractor algorithm\n",
    "    track = np.float32(track)\n",
    "    track = essentia.array(track)\n",
    "    pool = extractor(track)\n",
    "    # First feature assignment \n",
    "    features = pool[intraFrame_features[0]]\n",
    "    for i in intraFrame_features[1:]:\n",
    "        # If not multidimensional feature, expands dimensions to allow concatenation\n",
    "        if len(pool[i].shape) > 1:\n",
    "            features = np.concatenate((features, pool[i]), axis = 1)\n",
    "        else:\n",
    "            features = np.concatenate((features, np.expand_dims(pool[i], axis = 1)), axis =1)\n",
    "    # Adds the frame's label column\n",
    "    features = np.concatenate((features, np.expand_dims(np.tile(label, features.shape[0]), axis = 1)), axis = 1)\n",
    "    return features\n",
    "\n",
    "aux = train_tracks[0].targets['vocals'].audio[:,0]*0.5 + train_tracks[0].targets['vocals'].audio[:,1]*0.5\n",
    "f  = extract_features(aux, intraFrame_features, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
