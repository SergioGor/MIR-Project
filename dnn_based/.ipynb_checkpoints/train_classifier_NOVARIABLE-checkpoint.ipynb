{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to GPU\n",
      "Epoch 1 starts...\n",
      "Epoch 1. Loss: 0.0142 (train) | 0.0188 (val). ACC: 79.8936%\n",
      "Epoch 2 starts...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "musdb18_path = '/home/enricguso/datasets/musdb18/'\n",
    "\n",
    "tcontext=120\n",
    "fft_size=1024\n",
    "split=0.8\n",
    "classes = ('vocals', 'drums', 'bass', 'other')\n",
    "class musDB_class_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, tcontext, split, mode):\n",
    "        self.root_dir = root_dir\n",
    "        self.tcontext = tcontext\n",
    "        self.split = split\n",
    "        self.mode = mode\n",
    "        with h5py.File(self.root_dir, 'r') as db:\n",
    "            # At which frequency index we split into train and val set:\n",
    "            self.train_end_f_ind = db['f_indexes'][+\n",
    "                np.where(db['f_indexes'][...] >= int(db['f_indexes'][-1]) * self.split)[0][0]]\n",
    "            # Number of STFT bins for the validation set\n",
    "            self.val_stftbins = db['f_indexes'][-1] - self.train_end_f_ind\n",
    "            self.f_indexes=db['f_indexes'][...]\n",
    "            \n",
    "    def __len__(self):\n",
    "        # Returns the length of the dataset\n",
    "        if self.mode == 'train':\n",
    "            lens = int((self.train_end_f_ind/self.tcontext))\n",
    "        else:\n",
    "            lens = int(self.val_stftbins/self.tcontext)\n",
    "        return lens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the slice using the index idx\n",
    "        with h5py.File(self.root_dir, 'r') as db:\n",
    "            if self.mode == 'train':\n",
    "                reader_head = idx\n",
    "            elif self.mode == 'val':\n",
    "                reader_head = idx + int(self.train_end_f_ind / self.tcontext)\n",
    "            # validation_audio mode: for inference. Provides a whole file with 50% overlap\n",
    "            track_mag = db['track_mag'][\n",
    "                        int(reader_head * self.tcontext):int(reader_head * self.tcontext + self.tcontext)]\n",
    "            track_mag = np.expand_dims(track_mag, 0)\n",
    "            label = db['label'][reader_head]\n",
    "            track_mag = torch.from_numpy(track_mag)\n",
    "\n",
    "            sample = {'input': track_mag, 'label': label}\n",
    "            \n",
    "        return sample\n",
    "\n",
    "train_dataset=musDB_class_dataset(musdb18_path + 'musdb_classify_tcontext_' + str(tcontext) + '.hdf5', tcontext, split, mode='train')\n",
    "\n",
    "val_dataset=musDB_class_dataset(musdb18_path + 'musdb_classify_tcontext_' + str(tcontext) + '.hdf5', tcontext, split, mode='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=30, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, tcontext, fft_size):\n",
    "        self.tcontext=tcontext\n",
    "        self.fft_size=fft_size\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1=nn.Conv2d(1, 16, (5,5), stride=(1,2))\n",
    "        self.bn1=nn.BatchNorm2d(16)\n",
    "        self.conv2=nn.Conv2d(16, 32, (5,5), stride=(1,2))\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.conv3=nn.Conv2d(32, 64, (5,5), stride=2)\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.conv4=nn.Conv2d(64, 128, (5,5), stride=2)\n",
    "        self.bn4=nn.BatchNorm2d(128)\n",
    "        self.conv5=nn.Conv2d(128, 256, (5,5), stride=2)\n",
    "        self.bn5=nn.BatchNorm2d(256)\n",
    "        self.conv6=nn.Conv2d(256, 512, (5,5), stride=2)\n",
    "        self.bn6=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.drop1 = nn.Dropout2d(p=0.5)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.drop3 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*4*5,512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=self.drop1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=self.drop2(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.drop3(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.bn4(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.bn5(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=self.conv6(x)\n",
    "        x=self.bn6(x)\n",
    "        x=self.lrelu(x)\n",
    "        x=x.view(-1, 512*4*5)\n",
    "        x=nn.functional.relu(self.fc1(x))\n",
    "        x=nn.functional.relu(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        \n",
    "        return x.squeeze()\n",
    "    \n",
    "    \n",
    "net=Net(tcontext, fft_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    print('Model sent to GPU')    \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "num_epochs=500\n",
    "\n",
    "train_loss=torch.zeros(num_epochs)\n",
    "val_loss=torch.zeros(num_epochs)\n",
    "val_accuracy=torch.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch '+str(epoch+1)+' starts...')\n",
    "    running_loss=0.0\n",
    "    for x in train_loader:\n",
    "        data = x['input']\n",
    "        label = x['label'].squeeze()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = torch.autograd.Variable(data.cuda())\n",
    "            label = torch.autograd.Variable(label.cuda())\n",
    "        else:\n",
    "            data = torch.autograd.Variable(data)\n",
    "            label = torch.autograd.Variable(label)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        running_loss+=loss.item()\n",
    "        optimizer.step()\n",
    "    train_loss[epoch]=running_loss/(len(train_loader)*train_loader.batch_size)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    for x in val_loader:\n",
    "        #disable dropout\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            data = x['input']\n",
    "            label = x['label'].squeeze()\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.autograd.Variable(data.cuda())\n",
    "                label = torch.autograd.Variable(label.cuda())\n",
    "            else:\n",
    "                data = torch.autograd.Variable(data)\n",
    "                label = torch.autograd.Variable(label)\n",
    "            outputs=net(data)\n",
    "            loss = criterion(outputs, label)\n",
    "            running_loss+=loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "    val_loss[epoch]=running_loss/(len(val_loader)*val_loader.batch_size)\n",
    "    val_accuracy[epoch] = 100*correct/total\n",
    "    #re-enable dropout\n",
    "    net.train()\n",
    "    print('Epoch ' + str(epoch+1) + '. Loss: '+'%.4f' %train_loss[epoch].numpy()+' (train) | '+'%.4f' %val_loss[epoch].numpy()+' (val). ACC: '+'%.4f' %val_accuracy[epoch].item()+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
